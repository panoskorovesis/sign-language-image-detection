{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9d3688c1-5cfa-431d-9be0-511ad7f0020c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 55500 files belonging to 37 classes.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from pprint import pprint\n",
    "\n",
    "dataset_path = \"/home/studio-lab-user/sign-language-image-detection/sign_datasets/sign-language-gesture-images-dataset/Gesture Image Data\"\n",
    "\n",
    "dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    dataset_path,\n",
    "    # Resize the images\n",
    "    image_size=(96, 96),\n",
    "    batch_size=64,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "def normalize_image(image, label):\n",
    "    precomputed_mean = [0.52732987, 0.4507709, 0.41209071]\n",
    "    precomputed_std = [0.19798545, 0.23537221, 0.26049182]\n",
    "\n",
    "    # Normalize the image\n",
    "    image = (image / 255.0 - precomputed_mean) / precomputed_std\n",
    "    return image, label\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "# Define the split ratio\n",
    "train_size = int(0.8 * len(dataset))  # 80% for training\n",
    "val_size = len(dataset) - train_size   # 20% for validation\n",
    "\n",
    "# Apply normalization to the datasets\n",
    "train_dataset = train_dataset.map(normalize_image)\n",
    "val_dataset = val_dataset.map(normalize_image)\n",
    "\n",
    "# Create the training and validation datasets\n",
    "train_dataset = dataset.take(train_size)\n",
    "val_dataset = dataset.skip(train_size)\n",
    "\n",
    "# Prefetching for performance\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_dataset = train_dataset.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_dataset = val_dataset.cache().prefetch(buffer_size=AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cc673c78-d138-4f81-b992-608ba8b1dc80",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 694/694 [00:14<00:00, 47.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44416\n",
      "{0,\n",
      " 1,\n",
      " 2,\n",
      " 3,\n",
      " 4,\n",
      " 5,\n",
      " 6,\n",
      " 7,\n",
      " 8,\n",
      " 9,\n",
      " 10,\n",
      " 11,\n",
      " 12,\n",
      " 13,\n",
      " 14,\n",
      " 15,\n",
      " 16,\n",
      " 17,\n",
      " 18,\n",
      " 19,\n",
      " 20,\n",
      " 21,\n",
      " 22,\n",
      " 23,\n",
      " 24,\n",
      " 25,\n",
      " 26,\n",
      " 27,\n",
      " 28,\n",
      " 29,\n",
      " 30,\n",
      " 31,\n",
      " 32,\n",
      " 33,\n",
      " 34,\n",
      " 35,\n",
      " 36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "total = 0\n",
    "unique_labels = set()\n",
    "for batch_images, batch_labels in tqdm(train_dataset):\n",
    "    total += len(batch_labels)\n",
    "    for label in batch_labels:\n",
    "        unique_labels.add(int(label))\n",
    "\n",
    "print(total)\n",
    "pprint(unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5e3e6c14-99c5-4667-8524-189c779f3149",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 174/174 [00:09<00:00, 18.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11084\n",
      "{0,\n",
      " 1,\n",
      " 2,\n",
      " 3,\n",
      " 4,\n",
      " 5,\n",
      " 6,\n",
      " 7,\n",
      " 8,\n",
      " 9,\n",
      " 10,\n",
      " 11,\n",
      " 12,\n",
      " 13,\n",
      " 14,\n",
      " 15,\n",
      " 16,\n",
      " 17,\n",
      " 18,\n",
      " 19,\n",
      " 20,\n",
      " 21,\n",
      " 22,\n",
      " 23,\n",
      " 24,\n",
      " 25,\n",
      " 26,\n",
      " 27,\n",
      " 28,\n",
      " 29,\n",
      " 30,\n",
      " 31,\n",
      " 32,\n",
      " 33,\n",
      " 34,\n",
      " 35,\n",
      " 36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "total = 0\n",
    "unique_labels = set()\n",
    "for batch_images, batch_labels in tqdm(val_dataset):\n",
    "    total += len(batch_labels)\n",
    "    for label in batch_labels:\n",
    "        unique_labels.add(int(label))\n",
    "\n",
    "print(total)\n",
    "pprint(unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "53496ffe-390f-4c1f-bb85-a0f3a747f1eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_10 (Flatten)        (None, 27648)             0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 500)               13824500  \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 37)                18537     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13843037 (52.81 MB)\n",
      "Trainable params: 13843037 (52.81 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "694/694 [==============================] - 118s 169ms/step - loss: 11.5951 - accuracy: 0.7448 - val_loss: 1.3612 - val_accuracy: 0.9339\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f828ae47820>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "    tf.keras.layers.Flatten(input_shape=(96, 96, 3)),\n",
    "    tf.keras.layers.Dense(500, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(len(class_names), activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "adam = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "model.compile(\n",
    "    optimizer=adam,\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics = [\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.fit(train_dataset, epochs=1, validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3b210bcf-df13-4d93-a5f8-45bf63a186f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_12 (Conv2D)          (None, 94, 94, 64)        1792      \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPooli  (None, 47, 47, 64)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 45, 45, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPooli  (None, 22, 22, 64)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 20, 20, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPooli  (None, 10, 10, 64)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_12 (Flatten)        (None, 6400)              0         \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 128)               819328    \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 37)                4773      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 899749 (3.43 MB)\n",
      "Trainable params: 899749 (3.43 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "694/694 [==============================] - 548s 789ms/step - loss: 0.3175 - accuracy: 0.9485 - val_loss: 0.0226 - val_accuracy: 0.9938\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, Dense, Flatten, Dropout, MaxPooling2D\n",
    "from keras.models import Sequential, save_model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, kernel_size=(3,3), activation = 'relu', input_shape=(96, 96 ,3) ))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size = (3, 3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size = (3, 3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dropout(0.20))\n",
    "model.add(Dense(37, activation = 'softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='Adam', metrics=['accuracy'], loss='sparse_categorical_crossentropy')\n",
    "history = model.fit(train_dataset,\n",
    "                    validation_data=val_dataset,\n",
    "                    epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c48d1869-3b8d-4895-a863-2bcad5dc3b6c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenetv2_1.00_96 (Funct  (None, 3, 3, 1280)        2257984   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " global_average_pooling2d_3  (None, 1280)              0         \n",
      "  (GlobalAveragePooling2D)                                       \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 128)               163968    \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 37)                4773      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2426725 (9.26 MB)\n",
      "Trainable params: 168741 (659.14 KB)\n",
      "Non-trainable params: 2257984 (8.61 MB)\n",
      "_________________________________________________________________\n",
      "None\n",
      "694/694 [==============================] - 229s 326ms/step - loss: 0.4905 - accuracy: 0.8766 - val_loss: 0.0704 - val_accuracy: 0.9837\n"
     ]
    }
   ],
   "source": [
    "base_model = tf.keras.applications.MobileNetV2(input_shape=(96, 96, 3),\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')\n",
    "\n",
    "# We dont want to train this model\n",
    "base_model.trainable = False\n",
    "\n",
    "# Add custom layers on top of the base model\n",
    "model = tf.keras.Sequential([\n",
    "    base_model,\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(len(class_names), activation='softmax')  # Adjust num_classes as needed\n",
    "])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_dataset,\n",
    "                    validation_data=val_dataset,\n",
    "                    epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcdf6c1-f62b-4eb7-bc46-98326983a8e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sagemaker-distribution:Python",
   "language": "python",
   "name": "conda-env-sagemaker-distribution-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
