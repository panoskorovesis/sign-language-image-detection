{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F \n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torch.utils.data import ConcatDataset\n",
    "import time\n",
    "\n",
    "USE_GPU = True\n",
    "dtype = torch.float32 # We will be using float\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# Constant to control how frequently we print train loss.\n",
    "print_every = -1\n",
    "print('using device:', device)\n",
    "\n",
    "path_to_store_the_plots = 'plots/flatten/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plots will be stored in: plots/ASL_Dataset\n",
      "Total samples: 165782\n",
      "Training set size: 116047\n",
      "Validation set size: 33156\n",
      "Test set size: 16579\n"
     ]
    }
   ],
   "source": [
    "# Define the path to the dataset\n",
    "#dataset_path = \"../../../sign_datasets/sign-language-gesture-images-dataset/Gesture Image Data\"\n",
    "#dataset_path = \"../../../sign_datasets/hagrid-classification-512p\"\n",
    "#dataset_path = \"../../../sign_datasets/hagrid-classification-512p-10-percent\"\n",
    "dataset_path = [\"../../../sign_datasets/american_sign_language_dataset/ASL_Dataset/Train\", \"../../../sign_datasets/american_sign_language_dataset/ASL_Dataset/Test\"]\n",
    "#dataset_path = [\"../../../sign_datasets/bengali-sign-language-dataset/RESIZED_DATASET\", \"../../../sign_datasets/bengali-sign-language-dataset/RESIZED_TESTING_DATA\"]\n",
    "#dataset_path = [\"../../../sign_datasets/kslc-kenyan-sign-language-dataset/train\", \"../../../sign_datasets/kslc-kenyan-sign-language-dataset/test\"]\n",
    "#dataset_path = \"../../../sign_datasets/AzSL Dataset\"\n",
    "\n",
    "# Define the batch size\n",
    "batch_size = 64\n",
    "if isinstance(dataset_path, str):\n",
    "    # Load the dataset without transformations\n",
    "    dataset = datasets.ImageFolder(root=dataset_path)\n",
    "    path_to_store_the_plots = 'plots/' + dataset_path.split('/')[-1]\n",
    "elif isinstance(dataset_path, list):\n",
    "    # Load all datasets using ImageFolder\n",
    "    datasets_list = [datasets.ImageFolder(root=path) for path in dataset_path]\n",
    "    # Combine all datasets\n",
    "    dataset = ConcatDataset(datasets_list)\n",
    "    path_to_store_the_plots = 'plots/' + dataset_path[0].split('/')[-2]\n",
    "\n",
    "# Check if the directory exists, and create it if it doesn't\n",
    "os.makedirs(path_to_store_the_plots, exist_ok=True)\n",
    "\n",
    "print(f\"Plots will be stored in: {path_to_store_the_plots}\")\n",
    "\n",
    "# Get the total number of samples\n",
    "total_samples = len(dataset)\n",
    "train_size = int(0.7 * total_samples)\n",
    "val_size = int(0.2 * total_samples)\n",
    "test_size = total_samples - train_size - val_size\n",
    "\n",
    "# Print the sizes of each split\n",
    "print(f\"Total samples: {total_samples}\")\n",
    "print(f\"Training set size: {train_size}\")\n",
    "print(f\"Validation set size: {val_size}\")\n",
    "print(f\"Test set size: {test_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class names: ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'Nothing', 'O', 'P', 'Q', 'R', 'S', 'Space', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n",
      "Train Batch - Images shape: torch.Size([64, 3, 400, 400])\n",
      "Train Batch - Labels shape: torch.Size([64])\n",
      "Train set size: 116047\n",
      "Validation set size: 33156\n",
      "Test set size: 16579\n",
      "Train DataLoader size: 1814\n",
      "Validation DataLoader size: 519\n",
      "Test DataLoader size: 260\n"
     ]
    }
   ],
   "source": [
    "# Already computed mean and std\n",
    "# sign-language-gesture-images-dataset/Gesture Image Data\"\n",
    "# computed_mean = [0.5273298025131226, 0.4507707953453064, 0.4120909869670868]\n",
    "# computed_std = [0.5632718205451965, 0.5085217952728271, 0.48751917481422424]\n",
    "\n",
    "# Hagrid\n",
    "# computed_mean = [0.5778126, 0.516726, 0.48417425]\n",
    "# computed_std = [0.25172076, 0.24928826, 0.24764916]\n",
    "\n",
    "# Hagrid 10%\n",
    "# computed_mean = [0.5810514688491821, 0.5178735852241516, 0.48736947774887085]\n",
    "# computed_std = [0.6329583525657654, 0.5746501684188843, 0.5465894937515259]\n",
    "\n",
    "# American Sign Language\n",
    "computed_mean = [0.52732987, 0.4507709, 0.41209071]\n",
    "computed_std = [0.19798545, 0.23537221, 0.26049182]\n",
    "\n",
    "# Bengali\n",
    "#computed_mean = [0.6287722587585449, 0.6092960834503174, 0.5825445055961609]\n",
    "#computed_std = [0.6499956250190735, 0.6389758586883545, 0.6195625066757202]\n",
    "\n",
    "# KSLC\n",
    "# computed_mean = [0.45728039741516113, 0.40885069966316223, 0.3974429965019226]\n",
    "# computed_std = [0.523685097694397, 0.47511494159698486, 0.4643438160419464]\n",
    "\n",
    "# azsl-dataset\n",
    "# computed_mean = [0.5590047240257263, 0.49885866045951843, 0.4555515944957733]\n",
    "# computed_std = [0.6033478379249573, 0.5458617806434631, 0.5077916383743286]\n",
    "\n",
    "\n",
    "# Build the transform pipeline\n",
    "transform_list = [\n",
    "    transforms.ToTensor(),  # Convert images to PyTorch tensors\n",
    "    transforms.Normalize(mean=computed_mean, std=computed_std)  # Normalize\n",
    "]\n",
    "\n",
    "if isinstance(dataset_path, str) and \"AzSL\" in dataset_path:\n",
    "    transform_list.insert(0, transforms.Resize((224, 224)))\n",
    "\n",
    "if isinstance(dataset_path, str) and \"hagrid\" in dataset_path:\n",
    "    transform_list.insert(0, transforms.Resize((512, 512)))\n",
    "\n",
    "# Create the final transform\n",
    "transform = transforms.Compose(transform_list)\n",
    "\n",
    "if isinstance(dataset_path, str):\n",
    "    # Load the dataset without transformations\n",
    "    dataset = datasets.ImageFolder(root=dataset_path, transform=transform)\n",
    "    class_names = dataset.classes\n",
    "elif isinstance(dataset_path, list):\n",
    "    # Load all datasets using ImageFolder\n",
    "    datasets_list = [datasets.ImageFolder(root=path, transform=transform) for path in dataset_path]\n",
    "    # Combine all datasets\n",
    "    dataset = ConcatDataset(datasets_list)\n",
    "    class_names = datasets_list[0].classes\n",
    "\n",
    "# Get class names\n",
    "print(\"Class names:\", class_names)\n",
    "\n",
    "# Split the dataset into train, validation, and test sets\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# Create DataLoaders for each split\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "# Example of iterating through the train DataLoader\n",
    "for images, labels in train_loader:\n",
    "    print(\"Train Batch - Images shape:\", images.shape)\n",
    "    print(\"Train Batch - Labels shape:\", labels.shape)\n",
    "    break\n",
    "\n",
    "# Print dataset sizes for verification\n",
    "print(f\"Train set size: {len(train_dataset)}\")\n",
    "print(f\"Validation set size: {len(val_dataset)}\")\n",
    "print(f\"Test set size: {len(test_dataset)}\")\n",
    "\n",
    "len_train_loader = len(train_loader)\n",
    "len_val_loader = len(val_loader)\n",
    "len_test_loader = len(test_loader)\n",
    "\n",
    "# Print DataLoader sizes for verification\n",
    "print(f\"Train DataLoader size: {len(train_loader)}\")\n",
    "print(f\"Validation DataLoader size: {len(val_loader)}\")\n",
    "print(f\"Test DataLoader size: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Width: 400, Height: 400\n"
     ]
    }
   ],
   "source": [
    "# Access the first image in the dataset\n",
    "image, label = train_loader.dataset[0]\n",
    "\n",
    "# Extract dimensions\n",
    "width = image.shape[1]\n",
    "height = image.shape[2]\n",
    "\n",
    "print(f\"Width: {width}, Height: {height}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy_part(loader, model, return_acc=False):\n",
    "\n",
    "    # Determine the split type\n",
    "    if len(loader) == len_train_loader:\n",
    "        split = 'train'\n",
    "    elif len(loader) == len_val_loader:\n",
    "        split = 'val'\n",
    "    elif len(loader) == len_test_loader:\n",
    "        split = 'test'\n",
    "\n",
    "    print(f'Checking accuracy on the {split} set')\n",
    "\n",
    "    # Init counters and placeholders\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Disable gradient computation as we don't train\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device, dtype=dtype)  # Move to device, e.g., GPU\n",
    "            y = y.to(device=device, dtype=torch.long)  # Use torch.long for labels\n",
    "\n",
    "            # Forward pass\n",
    "            scores = model(x)\n",
    "            _, preds = scores.max(1)  # Get predicted class -> highest score\n",
    "\n",
    "            # Collect all predictions and labels for confusion matrix\n",
    "            all_preds.append(preds.cpu())  # Append to list, move to CPU for numpy\n",
    "            all_labels.append(y.cpu())    # Append to list, move to CPU for numpy\n",
    "\n",
    "            # Count correct predictions and total samples\n",
    "            correct_predictions = preds == y  # True if correct - False otherwise\n",
    "            num_correct += correct_predictions.sum().item()\n",
    "            num_samples += preds.size(0)\n",
    "\n",
    "    # Compute accuracy\n",
    "    acc = float(num_correct) / num_samples\n",
    "    print('Got %d / %d correct (%.2f%%)' % (num_correct, num_samples, 100 * acc))\n",
    "\n",
    "    # For test set: plot confusion matrix\n",
    "    if split == 'test':\n",
    "        all_preds = torch.cat(all_preds).numpy()  # Flatten and convert to numpy\n",
    "        all_labels = torch.cat(all_labels).numpy()\n",
    "\n",
    "        # Compute confusion matrix\n",
    "        conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "        # Plot confusion matrix\n",
    "        plt.figure(figsize=(20, 20))\n",
    "        sns.heatmap(\n",
    "            conf_matrix,\n",
    "            annot=True,\n",
    "            fmt='d',\n",
    "            cmap='Greens',\n",
    "            linewidths=0.5,\n",
    "            xticklabels=class_names,\n",
    "            yticklabels=class_names\n",
    "        )\n",
    "        plt.xlabel('Predicted labels')\n",
    "        plt.ylabel('True labels')\n",
    "        plt.title('Confusion Matrix with Actual Class Labels')\n",
    "        plt.savefig(path_to_store_the_plots + '/confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "\n",
    "    if return_acc:\n",
    "        return 100 * acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_part(model, optimizer, epochs=1, scheduler = None, return_acc = False, check_train_set = False, check_test_set = False):\n",
    "    \n",
    "    # List to store validation and train accuracies at each epoch where needed\n",
    "    val_accs = []\n",
    "    train_accs = []\n",
    "    losses = []\n",
    "    val_losses = [] \n",
    "    \n",
    "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "    for e in range(epochs):\n",
    "        for t, (x, y) in enumerate(train_loader):\n",
    "            model.train()  # put model to training mode\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "\n",
    "            scores = model(x)\n",
    "            loss = F.cross_entropy(scores, y)\n",
    "\n",
    "            # Zero out all of the gradients for the variables which the optimizer\n",
    "            # will update.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # This is the backwards pass: compute the gradient of the loss with\n",
    "            # respect to each  parameter of the model.\n",
    "            loss.backward()\n",
    "\n",
    "            # Actually update the parameters of the model using the gradients\n",
    "            # computed by the backwards pass.\n",
    "            optimizer.step()\n",
    "\n",
    "            if t+1 % print_every == 0 and print_every!=-1 :\n",
    "                print('Iteration %d, loss = %.4f' % (t, loss.item()))\n",
    "                check_accuracy_part(val_loader, model)\n",
    "                print()\n",
    "                \n",
    "        losses.append(loss.item())\n",
    "        print(f\"Training Loss after epoch {e+1}: {loss.item()}\")\n",
    "        # Step the scheduler after each epoch to adjust the learning rate if needed\n",
    "        if scheduler:\n",
    "            if isinstance(scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
    "                # If the scheduler is of type ReduceLROnPlateau, use validation loss for adjustment\n",
    "                model.eval()  # Set model to evaluation mode\n",
    "                val_loss = 0.0  # Initialize validation loss accumulator\n",
    "                with torch.no_grad():  # No need to compute gradients during validation\n",
    "                    for data, target in val_loader:\n",
    "                        data, target = data.to(device=device, dtype=dtype), target.to(device=device, dtype=torch.long)\n",
    "                        output = model(data)\n",
    "                        loss = F.cross_entropy(output, target)\n",
    "                        val_loss += loss.item()  # Accumulate the validation loss\n",
    "\n",
    "                val_loss /= len(val_loader)  # Average the validation loss\n",
    "                scheduler.step(val_loss)  # Step the scheduler based on the validation loss\n",
    "            else:\n",
    "                scheduler.step()  # Step the scheduler for other types of schedulers\n",
    "\n",
    "        # Calculate validation loss for the epoch\n",
    "        model.eval()  # Set model to evaluation mode\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for data, target in val_loader:\n",
    "                data, target = data.to(device=device, dtype=dtype), target.to(device=device, dtype=torch.long)\n",
    "                output = model(data)\n",
    "                loss = F.cross_entropy(output, target)\n",
    "                val_loss += loss.item()\n",
    "        val_loss /= len(val_loader)  # Average validation loss\n",
    "        val_losses.append(val_loss)  # Append validation loss to list\n",
    "        \n",
    "        # After each epoch, check accuracies\n",
    "        val_acc = check_accuracy_part(val_loader, model, return_acc=True)\n",
    "        val_accs.append(val_acc)\n",
    "        \n",
    "        print(f\"Validation Accuracy after epoch {e+1}: {val_acc:.2f}%\")\n",
    "        print(f\"Validation Loss after epoch {e+1}: {val_loss:.2f}\")\n",
    "        \n",
    "        # Return accuracies if requested\n",
    "        if check_train_set:\n",
    "            train_acc = check_accuracy_part(train_loader, model, return_acc=True)\n",
    "            train_accs.append(train_acc)\n",
    "            print(f\"Training Accuracy after epoch {e+1}: {train_acc:.2f}%\")\n",
    "\n",
    "    # Return accuracies if requested\n",
    "    if return_acc:\n",
    "        if check_train_set and check_test_set:\n",
    "            test_acc = check_accuracy_part(test_loader, model, return_acc=True)  # Check test set accuracy\n",
    "            return val_accs, train_accs, test_acc, losses, val_losses  # Return the most recent validation accuracy and the test accuracy\n",
    "        if check_train_set:  # If requested, return both validation and training accuracies\n",
    "            return val_accs, train_accs, losses, val_losses\n",
    "        if check_test_set:  # If requested, return the validation accuracy and test accuracy\n",
    "            test_acc = check_accuracy_part(test_loader, model, return_acc=True)  # Check test set accuracy\n",
    "            return val_accs, test_acc, losses, val_losses  # Return the most recent validation accuracy and the test accuracy\n",
    "        return val_accs, losses, val_losses  # Return only validation accuracies if no other set (train or test) is specified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(x):\n",
    "    N = x.shape[0] # read in N, C, H, W\n",
    "    return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return flatten(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss after epoch 1: 0.007412060163915157\n",
      "Checking accuracy on the val set\n"
     ]
    }
   ],
   "source": [
    "hidden_layer_size = 500\n",
    "learning_rate = 1e-3\n",
    "num_classes = len(class_names)\n",
    "\n",
    "model = nn.Sequential(\n",
    "    Flatten(),\n",
    "    nn.Linear(3 * width * height, hidden_layer_size),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(hidden_layer_size, num_classes),\n",
    ")\n",
    "\n",
    "model = model.to(device=device)\n",
    "\n",
    "\n",
    "# you can use Nesterov momentum in optim.SGD\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate,\n",
    "                     momentum=0.9, nesterov=True)\n",
    "\n",
    "# Start the timer\n",
    "start_time = time.time()\n",
    "val_accs, train_accs, test_acc, losses, val_losses = train_part(model, optimizer,epochs=10, return_acc=True, check_train_set = True, check_test_set = True)\n",
    "# Stop the timer\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "# Print the validation and test accuracies\n",
    "print()\n",
    "print('########### Final Results ###########')\n",
    "print(\"Elapsed Time: {:.2f} seconds\".format(elapsed_time))\n",
    "print(\"Validation Accuracy:\", val_accs[-1])\n",
    "print(\"Test Accuracy:\", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot accuracy\n",
    "epochs = range(len(val_accs))\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(epochs, train_accs, 'r', label='Training Accuracy')\n",
    "plt.plot(epochs, val_accs, 'b', label='Validation Accuracy')\n",
    "plt.title('Training vs Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.savefig(path_to_store_the_plots + '/Accuracy.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Plot loss\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(epochs, losses, 'r', label='Training Loss')\n",
    "plt.plot(epochs, val_losses, 'b', label='Validation Loss')\n",
    "plt.title('Training vs Validation Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid(True)\n",
    "plt.savefig(path_to_store_the_plots + '/Loss.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
