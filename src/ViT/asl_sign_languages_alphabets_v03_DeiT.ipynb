{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    " # for google colaab setup\n",
    "import sys\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%cd /content/drive/MyDrive/projects/sign-language-image-detection\n",
    "!pip install virtualenv\n",
    "!pip install -r requirements.txt\n",
    "!python -m ipykernel install --user --name=sl_detection --display-name \"SL Detection\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Install required packages (add `--upgrade` to ensure the latest versions)\n",
    "!pip install --upgrade transformers datasets torch torchvision accelerate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "from transformers import (\n",
    "    DeiTImageProcessor,\n",
    "    DeiTForImageClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    ")\n",
    "from torchvision.transforms import Normalize, ToTensor, Resize\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Load the ASL Sign Language Alphabets dataset from Hugging Face\n",
    "dataset_name = \"Marxulia/asl_sign_languages_alphabets_v03\"\n",
    "dataset = load_dataset(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate sizes for train, validation, and test splits\n",
    "train_size = int(0.7 * len(dataset['train']))  # 70% for training\n",
    "val_size = int(0.1 * len(dataset['train']))    # 10% for validation\n",
    "test_size = len(dataset['train']) - train_size - val_size  # Remaining for testing\n",
    "\n",
    "# Split dataset into train, validation, and test sets\n",
    "train_ds = dataset['train'].select(range(0, train_size))\n",
    "val_ds = dataset['train'].select(range(train_size, train_size + val_size))\n",
    "test_ds = dataset['train'].select(range(train_size + val_size, len(dataset['train'])))\n",
    "dataset_splits = DatasetDict({\n",
    "    \"train\": train_ds,\n",
    "    \"validation\": val_ds,\n",
    "    \"test\": test_ds\n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "# Load the DeiT image processor\n",
    "model_name = \"facebook/deit-tiny-distilled-patch16-224\"\n",
    "processor = DeiTImageProcessor.from_pretrained(model_name)\n",
    "\n",
    "# Define image normalization and resizing\n",
    "image_mean, image_std = processor.image_mean, processor.image_std\n",
    "normalize = Normalize(mean=image_mean, std=image_std)\n",
    "image_size = processor.size[\"height\"]\n",
    "resize = Resize((image_size, image_size))\n",
    "\n",
    "# Define transformation function\n",
    "def apply_transforms(examples):\n",
    "    examples[\"pixel_values\"] = [\n",
    "        normalize(ToTensor()(resize(image.convert(\"RGB\")))) for image in examples[\"image\"]\n",
    "    ]\n",
    "    return examples\n",
    "\n",
    "# Apply transformations to dataset splits\n",
    "dataset_splits[\"train\"].set_transform(apply_transforms)\n",
    "dataset_splits[\"validation\"].set_transform(apply_transforms)\n",
    "dataset_splits[\"test\"].set_transform(apply_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Map label IDs to labels\n",
    "id2label = {id: label for id, label in enumerate(train_ds.features[\"label\"].names)}\n",
    "label2id = {label: id for id, label in id2label.items()}\n",
    "\n",
    "# Load the DeiT model\n",
    "model = DeiTForImageClassification.from_pretrained(\n",
    "    model_name,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    "    ignore_mismatched_sizes=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Define a collate function for batching\n",
    "def collate_fn(examples):\n",
    "    pixel_values = torch.stack([example[\"pixel_values\"] for example in examples])\n",
    "    labels = torch.tensor([example[\"label\"] for example in examples])\n",
    "    return {\"pixel_values\": pixel_values, \"labels\": labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Define training arguments\n",
    "train_args = TrainingArguments(\n",
    "    output_dir=\"output-models-deit\",\n",
    "    save_total_limit=2,\n",
    "    evaluation_strategy=\"epoch\",  # Evaluate at the end of each epoch\n",
    "    save_strategy=\"epoch\",       # Save the model at the end of each epoch\n",
    "    learning_rate=1e-3,\n",
    "    per_device_train_batch_size=64,\n",
    "    per_device_eval_batch_size=64,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    logging_dir=\"logs\",\n",
    "    remove_unused_columns=False,\n",
    "    report_to=\"none\",  # Disable W&B logging\n",
    "    local_rank=-1       # Disable distributed training\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=train_args,\n",
    "    train_dataset=dataset_splits[\"train\"],\n",
    "    eval_dataset=dataset_splits[\"validation\"],\n",
    "    data_collator=collate_fn,\n",
    "    tokenizer=processor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "outputs = trainer.predict(dataset_splits[\"test\"])\n",
    "\n",
    "\n",
    "print(outputs.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Get predictions and true labels\n",
    "y_true = outputs.label_ids\n",
    "y_pred = outputs.predictions.argmax(1)\n",
    "\n",
    "# Get label names\n",
    "labels = train_ds.features[\"label\"].names\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Display confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "disp.plot(cmap='Blues')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate the recall scores for each class\n",
    "recall = recall_score(y_true, y_pred, average=None)\n",
    "\n",
    "# Print the recall for each class\n",
    "print(\"\\nRecall Scores:\")\n",
    "for label, score in zip(labels, recall):\n",
    "    print(f\"Recall for {label}: {score:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
